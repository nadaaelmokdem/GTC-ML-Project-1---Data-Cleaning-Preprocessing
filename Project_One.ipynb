{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GTC ML Project 1 - Data Cleaning & Preprocessing\n",
        "\n",
        "This project focuses on preparing the **hotel bookings dataset** for machine learning.  \n",
        "The business problem is predicting booking cancellations, but our task is only **data preprocessing** — not building the final model.  \n",
        "\n",
        "We will follow three phases:\n",
        "1. Exploratory Data Analysis (EDA) & Data Quality Report  \n",
        "2. Data Cleaning  \n",
        "3. Feature Engineering & Preprocessing\n"
      ],
      "metadata": {
        "id": "WZEOnoplT8mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Objective:*** Build a robust data preprocessing pipeline for a hotel booking cancellation prediction model.\n",
        "#### ***Business Problem:*** The revenue team has identified that last-minute booking cancellations significantly impact profitability. Your task is not to build the final model, but to prepare the raw data for it. The quality of your data cleaning will directly determine the model's future success."
      ],
      "metadata": {
        "id": "_qa_yrQhUD_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1: Exploratory Data Analysis (EDA) & Data Quality Report\n",
        "\n",
        "In this phase, we:\n",
        "- Loaded the dataset and explored its structure.\n",
        "- Generated summary statistics.\n",
        "- Identified missing values and visualized them.\n",
        "- Detected outliers in key numerical features (`adr`, `lead_time`).\n",
        "- Documented the main data quality issues.\n"
      ],
      "metadata": {
        "id": "U_pMZqUTUfbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Load the Dataset\n",
        "Upload the hotel bookings dataset into Google Colab and read it using Pandas.\n"
      ],
      "metadata": {
        "id": "RYC9RzP6Usje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "uzfqLXhpU36q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('hotel_bookings - hotel_bookings.csv')"
      ],
      "metadata": {
        "id": "H5tLPaDKXxO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Import the Libraries\n",
        "Import all the required libraries for data analysis and visualization.\n"
      ],
      "metadata": {
        "id": "_qT3PFtdVA4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SQllJUlNXsf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Dataset Overview\n",
        "Check the shape of the dataset, basic info, and summary statistics.\n"
      ],
      "metadata": {
        "id": "eum6iM9dXMwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of dataset:\", df.shape)\n",
        "print(\"\\n--- Info ---\")\n",
        "print(df.info())\n",
        "print(\"\\n--- Summary Statistics ---\")\n",
        "print(df.describe(include=\"all\"))"
      ],
      "metadata": {
        "id": "45OnhrDCXO8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Missing Values\n",
        "Check for missing values and visualize them with a heatmap.\n"
      ],
      "metadata": {
        "id": "tyEfPxnPYBHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "7Sa6rjBFYGWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(df.isnull())\n",
        "plt.title(\"Missing Values\", fontsize=16)\n",
        "plt.xlabel(\"Columns\", fontsize=15)\n",
        "plt.ylabel(\"Rows\", fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RVjXVjMTYdyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Outlier Detection\n",
        "Detect outliers in important numeric columns like `adr` and `lead_time` using boxplots and the IQR method.\n"
      ],
      "metadata": {
        "id": "H-Cm5dxNkXWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(x=df[\"adr\"])\n",
        "plt.title(\"Outliers in ADR\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(x=df[\"lead_time\"])\n",
        "plt.title(\"Outliers in Lead Time\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P-KsWkzvg4Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2: Data Cleaning\n",
        "\n",
        "In this phase, we:\n",
        "- Handled missing values:\n",
        "  - `company`, `agent` → replaced with \"None\" or `0`\n",
        "  - `country` → imputed with most frequent value\n",
        "  - `children` → imputed with median\n",
        "- Removed duplicate rows.\n",
        "- Handled outliers in `adr` by capping values above 1000.\n",
        "- Fixed data types (converted date columns).\n"
      ],
      "metadata": {
        "id": "vbe9aswFiPQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Handle Missing Values\n",
        "- company → \"None\"  \n",
        "- agent → 0  \n",
        "- country → most frequent value  \n",
        "- children → median\n"
      ],
      "metadata": {
        "id": "kqA5I6qgkh8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"company\"].fillna(\"None\", inplace=True)\n",
        "df[\"agent\"].fillna(0, inplace=True)\n",
        "\n",
        "df[\"country\"].fillna(df[\"country\"].mode()[0], inplace=True)\n",
        "\n",
        "df[\"children\"].fillna(df[\"children\"].median(), inplace=True)\n"
      ],
      "metadata": {
        "id": "wl479XHric5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Remove Duplicates\n",
        "Drop duplicate rows to avoid data repetition.\n"
      ],
      "metadata": {
        "id": "H3j53FYWlt-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before removing duplicates:\", df.shape)\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(\"After removing duplicates:\", df.shape)\n"
      ],
      "metadata": {
        "id": "SvvMzK_NinIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Handle Outliers\n",
        "Cap extreme ADR values above 1000 to reduce skew.\n"
      ],
      "metadata": {
        "id": "xVe_PGRqlxOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max ADR before capping:\", df[\"adr\"].max())\n",
        "\n",
        "df[\"adr\"] = df[\"adr\"].clip(upper=1000)\n",
        "\n",
        "print(\"Max ADR after capping:\", df[\"adr\"].max())\n"
      ],
      "metadata": {
        "id": "kfYAGdwuirmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Fix Data Types\n",
        "Convert date columns (like `reservation_status_date`) to datetime format.\n"
      ],
      "metadata": {
        "id": "PnK5SpwYl2NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"reservation_status_date\"] = pd.to_datetime(df[\"reservation_status_date\"], errors=\"coerce\")\n",
        "\n",
        "print(\"Data types after conversion:\")\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "id": "zTgF1UnJivej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Remaining Missing Values:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "k7CqLAYMiysx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3: Feature Engineering & Preprocessing\n",
        "\n",
        "In this phase, we:\n",
        "- Created new features:\n",
        "  - `total_guests` = adults + children + babies\n",
        "  - `total_nights` = stays_in_weekend_nights + stays_in_week_nights\n",
        "  - `is_family` = binary flag for bookings with children/babies\n",
        "- Encoded categorical variables:\n",
        "  - One-Hot Encoding for `meal` and `market_segment`\n",
        "  - Grouped rare `country` values into \"Other\"\n",
        "- Removed data leakage columns (`reservation_status`, `reservation_status_date`).\n",
        "- Split the dataset into training and testing sets (80% / 20%).\n"
      ],
      "metadata": {
        "id": "xqOnMY2Ui9a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10: Create New Features\n",
        "- total_guests  \n",
        "- total_nights  \n",
        "- is_family (binary flag for families)\n"
      ],
      "metadata": {
        "id": "bTWwqu0ekwXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"total_guests\"] = df[\"adults\"] + df[\"children\"] + df[\"babies\"]\n",
        "\n",
        "df[\"total_nights\"] = df[\"stays_in_weekend_nights\"] + df[\"stays_in_week_nights\"]\n",
        "\n",
        "df[\"is_family\"] = df.apply(lambda row: 1 if (row[\"children\"] + row[\"babies\"]) > 0 else 0, axis=1)\n"
      ],
      "metadata": {
        "id": "GQoVtkj9i_DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11: Encode Categorical Variables\n",
        "- One-Hot Encoding for low-cardinality categories  \n",
        "- Group rare countries into \"Other\"\n"
      ],
      "metadata": {
        "id": "YStf123Xk0s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=[\"meal\", \"market_segment\"], drop_first=True)\n",
        "\n",
        "country_counts = df[\"country\"].value_counts()\n",
        "rare_countries = country_counts[country_counts < 100].index\n",
        "df[\"country\"] = df[\"country\"].replace(rare_countries, \"Other\")\n"
      ],
      "metadata": {
        "id": "IA4y9n_PjEJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 12: Remove Data Leakage\n",
        "Drop reservation_status and reservation_status_date.\n"
      ],
      "metadata": {
        "id": "gf0xN-iNk8Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"reservation_status\", \"reservation_status_date\"], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "3VD4Hl4cjH6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 13: Train-Test Split\n",
        "Split the dataset into 80% training and 20% testing sets.\n"
      ],
      "metadata": {
        "id": "ufPrjOTok_8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", train.shape)\n",
        "print(\"Testing set shape:\", test.shape)\n"
      ],
      "metadata": {
        "id": "3m1oEwXPjLNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Summary\n",
        "\n",
        "The dataset is now fully cleaned and preprocessed.  \n",
        "Key improvements made:\n",
        "- Missing values handled.\n",
        "- Outliers capped.\n",
        "- Duplicates removed.\n",
        "- Dates converted to proper format.\n",
        "- New features engineered.\n",
        "- Categorical variables encoded.\n",
        "- Data leakage removed.\n",
        "\n"
      ],
      "metadata": {
        "id": "A5PLIn7cj45Y"
      }
    }
  ]
}